#!/usr/bin/env python3
"""
å¹¶å‘æ€§èƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•Gunicornç”Ÿäº§æœåŠ¡å™¨çš„å¹¶å‘æ€§èƒ½
"""

import asyncio
import aiohttp
import time
import json
import psutil
import statistics
from datetime import datetime

# æµ‹è¯•é…ç½®
BASE_URL = "http://127.0.0.1:8001"

# æµ‹è¯•è¯·æ±‚ä½“
TEST_REQUEST = {
    "model": "qwen-0.5b",
    "messages": [
        {"role": "user", "content": "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹ã€‚"}
    ],
    "max_tokens": 100,
    "temperature": 0.7,
    "stream": False
}

class ConcurrentTester:
    def __init__(self):
        self.results = []
        self.start_time = None
        self.end_time = None
        
    async def single_request(self, session, request_id):
        """å•ä¸ªè¯·æ±‚"""
        start_time = time.time()
        
        try:
            async with session.post(
                f"{BASE_URL}/v1/chat/completions",
                json=TEST_REQUEST,
                timeout=aiohttp.ClientTimeout(total=60)
            ) as response:
                
                if response.status == 200:
                    data = await response.json()
                    end_time = time.time()
                    
                    # æå–tokenä¿¡æ¯
                    content = data.get('choices', [{}])[0].get('message', {}).get('content', '')
                    tokens = len(content.split()) if content else 0
                    response_time = end_time - start_time
                    
                    return {
                        'request_id': request_id,
                        'success': True,
                        'response_time': response_time,
                        'tokens': tokens,
                        'tokens_per_second': tokens / response_time if response_time > 0 else 0,
                        'status_code': response.status,
                        'content': content
                    }
                else:
                    end_time = time.time()
                    error_text = await response.text()
                    return {
                        'request_id': request_id,
                        'success': False,
                        'response_time': end_time - start_time,
                        'tokens': 0,
                        'tokens_per_second': 0,
                        'status_code': response.status,
                        'error': error_text[:200]
                    }
                    
        except Exception as e:
            end_time = time.time()
            return {
                'request_id': request_id,
                'success': False,
                'response_time': end_time - start_time,
                'tokens': 0,
                'tokens_per_second': 0,
                'status_code': None,
                'error': str(e)
            }

    async def run_concurrent_test(self, concurrent_count, total_requests):
        """è¿è¡Œå¹¶å‘æµ‹è¯•"""
        print(f"\nğŸ”„ å¼€å§‹å¹¶å‘æµ‹è¯•: {concurrent_count}å¹¶å‘, {total_requests}ä¸ªè¯·æ±‚")
        
        self.results = []
        self.start_time = time.time()
        
        # è·å–ç³»ç»Ÿåˆå§‹çŠ¶æ€
        initial_cpu = psutil.cpu_percent(interval=1)
        initial_memory = psutil.virtual_memory()
        
        async with aiohttp.ClientSession() as session:
            # åˆ›å»ºä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°
            semaphore = asyncio.Semaphore(concurrent_count)
            
            async def limited_request(request_id):
                async with semaphore:
                    return await self.single_request(session, request_id)
            
            # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
            tasks = [limited_request(i) for i in range(total_requests)]
            
            # å¹¶å‘æ‰§è¡Œ
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # å¤„ç†ç»“æœ
            for result in results:
                if isinstance(result, Exception):
                    self.results.append({
                        'request_id': -1,
                        'success': False,
                        'response_time': 0,
                        'tokens': 0,
                        'tokens_per_second': 0,
                        'status_code': None,
                        'error': str(result)
                    })
                else:
                    self.results.append(result)
        
        self.end_time = time.time()
        
        # è·å–ç³»ç»Ÿç»“æŸçŠ¶æ€
        final_cpu = psutil.cpu_percent(interval=1)
        final_memory = psutil.virtual_memory()
        
        # åˆ†æç»“æœ
        return self.analyze_results(
            concurrent_count, 
            initial_cpu, final_cpu, 
            initial_memory, final_memory
        )

    def analyze_results(self, concurrent_count, initial_cpu, final_cpu, initial_memory, final_memory):
        """åˆ†ææµ‹è¯•ç»“æœ"""
        total_time = self.end_time - self.start_time
        successful_results = [r for r in self.results if r['success']]
        failed_results = [r for r in self.results if not r['success']]
        
        if not successful_results:
            return {
                'concurrent_count': concurrent_count,
                'total_requests': len(self.results),
                'successful_requests': 0,
                'failed_requests': len(failed_results),
                'success_rate': 0.0,
                'total_time': total_time,
                'requests_per_second': 0.0,
                'avg_response_time': 0.0,
                'min_response_time': 0.0,
                'max_response_time': 0.0,
                'avg_tokens_per_second': 0.0,
                'cpu_usage_change': final_cpu - initial_cpu,
                'memory_usage_change': final_memory.percent - initial_memory.percent,
                'errors': [r.get('error', 'Unknown') for r in failed_results[:5]]
            }
        
        response_times = [r['response_time'] for r in successful_results]
        tokens_per_second = [r['tokens_per_second'] for r in successful_results if r['tokens_per_second'] > 0]
        
        return {
            'concurrent_count': concurrent_count,
            'total_requests': len(self.results),
            'successful_requests': len(successful_results),
            'failed_requests': len(failed_results),
            'success_rate': len(successful_results) / len(self.results) * 100,
            'total_time': total_time,
            'requests_per_second': len(successful_results) / total_time if total_time > 0 else 0,
            'avg_response_time': statistics.mean(response_times) if response_times else 0,
            'min_response_time': min(response_times) if response_times else 0,
            'max_response_time': max(response_times) if response_times else 0,
            'p95_response_time': statistics.quantiles(response_times, n=20)[18] if len(response_times) >= 20 else (max(response_times) if response_times else 0),
            'avg_tokens_per_second': statistics.mean(tokens_per_second) if tokens_per_second else 0,
            'cpu_usage_change': final_cpu - initial_cpu,
            'memory_usage_change': final_memory.percent - initial_memory.percent,
            'errors': [r.get('error', 'Unknown') for r in failed_results[:3]]
        }

    def print_results(self, stats):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        print(f"\nğŸ“Š æµ‹è¯•ç»“æœ - {stats['concurrent_count']}å¹¶å‘:")
        print(f"   æ€»è¯·æ±‚æ•°: {stats['total_requests']}")
        print(f"   æˆåŠŸè¯·æ±‚: {stats['successful_requests']}")
        print(f"   å¤±è´¥è¯·æ±‚: {stats['failed_requests']}")
        print(f"   æˆåŠŸç‡: {stats['success_rate']:.1f}%")
        print(f"   æ€»è€—æ—¶: {stats['total_time']:.2f}ç§’")
        print(f"   ååé‡: {stats['requests_per_second']:.2f} è¯·æ±‚/ç§’")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {stats['avg_response_time']:.3f}ç§’")
        print(f"   æœ€å¿«å“åº”: {stats['min_response_time']:.3f}ç§’")
        print(f"   æœ€æ…¢å“åº”: {stats['max_response_time']:.3f}ç§’")
        print(f"   P95å“åº”æ—¶é—´: {stats['p95_response_time']:.3f}ç§’")
        print(f"   å¹³å‡Tokenç”Ÿæˆé€Ÿåº¦: {stats['avg_tokens_per_second']:.1f} tokens/ç§’")
        print(f"   CPUä½¿ç”¨å˜åŒ–: {stats['cpu_usage_change']:+.1f}%")
        print(f"   å†…å­˜ä½¿ç”¨å˜åŒ–: {stats['memory_usage_change']:+.1f}%")
        
        if stats['errors']:
            print(f"   ä¸»è¦é”™è¯¯:")
            for i, error in enumerate(stats['errors'], 1):
                print(f"     {i}. {error}")

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Gunicornç”Ÿäº§æœåŠ¡å™¨å¹¶å‘æ€§èƒ½æµ‹è¯•")
    print("="*60)
    
    tester = ConcurrentTester()
    all_results = []
    
    # æµ‹è¯•ä¸åŒå¹¶å‘çº§åˆ«
    test_configs = [
        (2, 10),   # 2å¹¶å‘, 10è¯·æ±‚
        (5, 15),   # 5å¹¶å‘, 15è¯·æ±‚  
        (8, 24),   # 8å¹¶å‘, 24è¯·æ±‚
        (10, 30),  # 10å¹¶å‘, 30è¯·æ±‚
        (15, 30),  # 15å¹¶å‘, 30è¯·æ±‚
        (20, 40),  # 20å¹¶å‘, 40è¯·æ±‚
    ]
    
    for concurrent_count, total_requests in test_configs:
        try:
            stats = await tester.run_concurrent_test(concurrent_count, total_requests)
            tester.print_results(stats)
            all_results.append(stats)
            
            # å¦‚æœæˆåŠŸç‡ä½äº50%ï¼Œåœæ­¢æµ‹è¯•
            if stats['success_rate'] < 50:
                print(f"\nâš ï¸ æˆåŠŸç‡è¿‡ä½({stats['success_rate']:.1f}%)ï¼Œåœæ­¢è¿›ä¸€æ­¥æµ‹è¯•")
                break
                
            # ä¼‘æ¯2ç§’åç»§ç»­ä¸‹ä¸€ç»„æµ‹è¯•
            await asyncio.sleep(2)
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•{concurrent_count}å¹¶å‘æ—¶å‡ºé”™: {e}")
            break
    
    # è¾“å‡ºæ±‡æ€»ç»“æœ
    print("\n" + "="*60)
    print("ğŸ“ˆ æ€§èƒ½æµ‹è¯•æ±‡æ€»")
    print("="*60)
    print(f"{'å¹¶å‘æ•°':<8} {'æˆåŠŸç‡':<8} {'ååé‡':<12} {'å¹³å‡å“åº”æ—¶é—´':<12} {'Tokené€Ÿåº¦':<12}")
    print("-"*60)
    
    for stats in all_results:
        print(f"{stats['concurrent_count']:<8} "
              f"{stats['success_rate']:<7.1f}% "
              f"{stats['requests_per_second']:<11.2f} "
              f"{stats['avg_response_time']:<11.3f} "
              f"{stats['avg_tokens_per_second']:<11.1f}")
    
    # æ‰¾å‡ºæœ€ä½³æ€§èƒ½ç‚¹
    if all_results:
        best_throughput = max(all_results, key=lambda x: x['requests_per_second'])
        best_success_rate = max(all_results, key=lambda x: x['success_rate'])
        
        print(f"\nğŸ¯ æ€§èƒ½å»ºè®®:")
        print(f"   æœ€é«˜ååé‡: {best_throughput['concurrent_count']}å¹¶å‘ "
              f"({best_throughput['requests_per_second']:.2f} è¯·æ±‚/ç§’)")
        print(f"   æœ€é«˜æˆåŠŸç‡: {best_success_rate['concurrent_count']}å¹¶å‘ "
              f"({best_success_rate['success_rate']:.1f}%)")
        
        # æ¨èé…ç½®
        stable_configs = [s for s in all_results if s['success_rate'] >= 95]
        if stable_configs:
            recommended = max(stable_configs, key=lambda x: x['requests_per_second'])
            print(f"   æ¨èé…ç½®: {recommended['concurrent_count']}å¹¶å‘ "
                  f"(æˆåŠŸç‡{recommended['success_rate']:.1f}%, "
                  f"ååé‡{recommended['requests_per_second']:.2f})")

if __name__ == "__main__":
    asyncio.run(main())