#!/usr/bin/env python3
"""
å‹åŠ›æµ‹è¯•è„šæœ¬
"""

import requests
import time
import json
import concurrent.futures
from datetime import datetime
import statistics

BASE_URL = "http://127.0.0.1:8001"
API_BASE = f"{BASE_URL}/v1"

def single_request(request_id):
    """å•ä¸ªè¯·æ±‚æµ‹è¯•"""
    try:
        start_time = time.time()
        
        payload = {
            "model": "qwen-0.5b",
            "messages": [
                {"role": "user", "content": f"æµ‹è¯•è¯·æ±‚ {request_id}: ä½ å¥½"}
            ],
            "max_tokens": 50,
            "temperature": 0.7  # ä¿®æ­£å‚æ•°å
        }
        
        response = requests.post(
            f"{API_BASE}/chat/completions",
            json=payload,
            headers={"Content-Type": "application/json"},
            timeout=30
        )
        
        response_time = time.time() - start_time
        
        return {
            "request_id": request_id,
            "status_code": response.status_code,
            "response_time": response_time,
            "success": response.status_code == 200,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        return {
            "request_id": request_id,
            "status_code": 0,
            "response_time": 0,
            "success": False,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

def run_concurrent_test(num_requests=10, num_workers=5):
    """å¹¶å‘æµ‹è¯•"""
    print(f"\nğŸš€ å¼€å§‹å¹¶å‘å‹åŠ›æµ‹è¯•")
    print(f"   æ€»è¯·æ±‚æ•°: {num_requests}")
    print(f"   å¹¶å‘çº¿ç¨‹: {num_workers}")
    print("=" * 50)
    
    results = []
    start_time = time.time()
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:
        futures = [executor.submit(single_request, i) for i in range(num_requests)]
        
        for future in concurrent.futures.as_completed(futures):
            result = future.result()
            results.append(result)
            
            # å®æ—¶æ˜¾ç¤ºè¿›åº¦
            if result["success"]:
                print(f"âœ… è¯·æ±‚ {result['request_id']}: {result['response_time']:.3f}s")
            else:
                print(f"âŒ è¯·æ±‚ {result['request_id']}: å¤±è´¥")
    
    total_time = time.time() - start_time
    
    # ç»Ÿè®¡åˆ†æ
    successful_requests = [r for r in results if r["success"]]
    failed_requests = [r for r in results if not r["success"]]
    
    if successful_requests:
        response_times = [r["response_time"] for r in successful_requests]
        avg_response_time = statistics.mean(response_times)
        min_response_time = min(response_times)
        max_response_time = max(response_times)
        median_response_time = statistics.median(response_times)
        
        if len(response_times) > 1:
            stdev_response_time = statistics.stdev(response_times)
        else:
            stdev_response_time = 0
    else:
        avg_response_time = 0
        min_response_time = 0
        max_response_time = 0
        median_response_time = 0
        stdev_response_time = 0
    
    print("\n" + "=" * 50)
    print("ğŸ“Š å‹åŠ›æµ‹è¯•ç»“æœ")
    print("=" * 50)
    print(f"âœ… æˆåŠŸè¯·æ±‚: {len(successful_requests)}/{num_requests}")
    print(f"âŒ å¤±è´¥è¯·æ±‚: {len(failed_requests)}/{num_requests}")
    print(f"ğŸ“ˆ æˆåŠŸç‡: {len(successful_requests)/num_requests*100:.1f}%")
    print(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f}ç§’")
    print(f"ğŸš€ ååé‡: {num_requests/total_time:.2f} è¯·æ±‚/ç§’")
    
    if successful_requests:
        print(f"\nğŸ“Š å“åº”æ—¶é—´ç»Ÿè®¡:")
        print(f"   å¹³å‡å€¼: {avg_response_time:.3f}ç§’")
        print(f"   ä¸­ä½æ•°: {median_response_time:.3f}ç§’")
        print(f"   æœ€å°å€¼: {min_response_time:.3f}ç§’")
        print(f"   æœ€å¤§å€¼: {max_response_time:.3f}ç§’")
        print(f"   æ ‡å‡†å·®: {stdev_response_time:.3f}ç§’")
    
    return results

def run_load_test():
    """æ¸è¿›å¼è´Ÿè½½æµ‹è¯•"""
    print("\nğŸ”¬ æ¸è¿›å¼è´Ÿè½½æµ‹è¯•")
    print("=" * 50)
    
    test_configs = [
        (10, 1, "ä½è´Ÿè½½æµ‹è¯•"),
        (20, 5, "ä¸­è´Ÿè½½æµ‹è¯•"),
        (50, 10, "é«˜è´Ÿè½½æµ‹è¯•"),
    ]
    
    all_results = []
    
    for num_requests, num_workers, test_name in test_configs:
        print(f"\nğŸ“ {test_name}")
        results = run_concurrent_test(num_requests, num_workers)
        all_results.append({
            "test_name": test_name,
            "config": {"requests": num_requests, "workers": num_workers},
            "results": results
        })
        
        # æµ‹è¯•é—´éš”
        print("\nâ¸ï¸ ç­‰å¾…5ç§’åç»§ç»­ä¸‹ä¸€è½®æµ‹è¯•...")
        time.sleep(5)
    
    return all_results

def check_service_health():
    """æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€"""
    print("ğŸ¥ æ£€æŸ¥æœåŠ¡çŠ¶æ€...")
    try:
        response = requests.get(f"{BASE_URL}/health", timeout=5)
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… æœåŠ¡çŠ¶æ€: {data.get('status', 'unknown')}")
            print(f"ğŸ“š å·²åŠ è½½æ¨¡å‹æ•°: {data.get('models', 0)}")
            return True
        else:
            print(f"âŒ æœåŠ¡å“åº”å¼‚å¸¸: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡: {e}")
        return False

def main():
    print("ğŸ¯ VLLM æ¨ç†æœåŠ¡å‹åŠ›æµ‹è¯•")
    print("=" * 50)
    
    # æ£€æŸ¥æœåŠ¡çŠ¶æ€
    if not check_service_health():
        print("âš ï¸ æœåŠ¡ä¸å¯ç”¨ï¼Œé€€å‡ºæµ‹è¯•")
        return
    
    # è¿è¡Œæµ‹è¯•
    print("\né€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. å¿«é€Ÿæµ‹è¯• (10ä¸ªè¯·æ±‚)")
    print("2. æ ‡å‡†å‹åŠ›æµ‹è¯• (50ä¸ªè¯·æ±‚)")
    print("3. æ¸è¿›å¼è´Ÿè½½æµ‹è¯•")
    
    choice = input("\nè¯·é€‰æ‹© (1-3): ").strip()
    
    if choice == "1":
        run_concurrent_test(10, 3)
    elif choice == "2":
        run_concurrent_test(50, 10)
    elif choice == "3":
        run_load_test()
    else:
        print("æ— æ•ˆé€‰æ‹©ï¼Œè¿è¡Œé»˜è®¤å¿«é€Ÿæµ‹è¯•")
        run_concurrent_test(10, 3)
    
    print("\nâœ¨ æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main()