#!/usr/bin/env python3
"""
VLLM è·¨å¹³å°æ¨ç†æœåŠ¡å¯åŠ¨è„šæœ¬
æ”¯æŒå¼€å‘å’Œç”Ÿäº§ç¯å¢ƒå¯åŠ¨
"""

import os
import sys
import argparse
import signal
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from src.utils import get_config, setup_logger
from src.api.app import create_app
from src.api.load_balanced_app import create_load_balanced_app


def handle_signal(signum, frame):
    """ä¿¡å·å¤„ç†"""
    print(f"\næ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­æœåŠ¡...")
    sys.exit(0)


def run_development():
    """å¼€å‘æ¨¡å¼å¯åŠ¨"""
    print("ğŸ”§ å¼€å‘æ¨¡å¼å¯åŠ¨")
    
    # è·å–é…ç½®å¹¶é€‰æ‹©åº”ç”¨ç±»å‹
    config = get_config()
    
    if config.inference_mode == "load_balance":
        print("âš–ï¸ è´Ÿè½½å‡è¡¡æ¨¡å¼")
        app = create_load_balanced_app(config)
    else:
        print("ğŸ¯ å•å®ä¾‹æ¨¡å¼")
        app = create_app(config)
    
    app_config = app.config['APP_CONFIG']
    
    print(f"ğŸ“ æœåŠ¡åœ°å€: http://{app_config.host}:{app_config.port}")
    print(f"ğŸ”§ æ¨ç†å¼•æ“: {app_config.inference_engine}")
    print(f"ğŸ“š OpenAI æ¥å£: http://{app_config.host}:{app_config.port}/v1/")
    print(f"ğŸ¥ å¥åº·æ£€æŸ¥: http://{app_config.host}:{app_config.port}/health")
    print(f"ğŸ› ï¸ ç®¡ç†æ¥å£: http://{app_config.host}:{app_config.port}/v1/system/status")
    
    if config.inference_mode == "load_balance":
        print(f"âš–ï¸ è´Ÿè½½å‡è¡¡ç­–ç•¥: {config.load_balance_strategy}")
        print(f"ğŸ”¢ é›†ç¾¤å®ä¾‹æ•°: {config.cluster_instances}")
        print(f"ğŸ“Š é›†ç¾¤çŠ¶æ€: http://{app_config.host}:{app_config.port}/v1/cluster/status")
    print("\næŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    
    # æ³¨å†Œä¿¡å·å¤„ç†
    signal.signal(signal.SIGINT, handle_signal)
    signal.signal(signal.SIGTERM, handle_signal)
    
    try:
        app.run(
            host=app_config.host,
            port=app_config.port,
            debug=app_config.debug,
            threaded=True,
            use_reloader=False  # é¿å…é‡å¤åˆå§‹åŒ–
        )
    except KeyboardInterrupt:
        print("\næœåŠ¡å·²åœæ­¢")


def run_production():
    """ç”Ÿäº§æ¨¡å¼å¯åŠ¨"""
    print("ğŸš€ ç”Ÿäº§æ¨¡å¼å¯åŠ¨")
    
    config = get_config()
    
    try:
        import gunicorn.app.wsgiapp as wsgi
    except ImportError:
        print("âŒ ç”Ÿäº§æ¨¡å¼éœ€è¦å®‰è£… gunicorn")
        print("è¯·è¿è¡Œ: pip install gunicorn")
        sys.exit(1)
    
    # æ ¹æ®æ¨ç†æ¨¡å¼é€‰æ‹©åº”ç”¨
    if config.inference_mode == "load_balance":
        print("âš–ï¸ è´Ÿè½½å‡è¡¡æ¨¡å¼")
        app_module = 'src.api.load_balanced_app:get_load_balanced_app()'
        print(f"âš–ï¸ è´Ÿè½½å‡è¡¡ç­–ç•¥: {config.load_balance_strategy}")
        print(f"ğŸ”¢ é›†ç¾¤å®ä¾‹æ•°: {config.cluster_instances}")
    else:
        print("ğŸ¯ å•å®ä¾‹æ¨¡å¼")
        app_module = 'src.api.app:get_app()'
    
    # è®¾ç½® Gunicorn å‚æ•°
    sys.argv = [
        'gunicorn',
        '--bind', f'{config.host}:{config.port}',
        '--workers', str(config.workers),
        '--worker-class', 'gevent',
        '--worker-connections', '1000',
        '--timeout', '300',
        '--keepalive', '5',
        '--max-requests', '1000',
        '--max-requests-jitter', '100',
        '--preload',
        '--access-logfile', '-',
        '--error-logfile', '-',
        app_module
    ]
    
    print(f"ğŸ“ æœåŠ¡åœ°å€: http://{config.host}:{config.port}")
    print(f"ğŸ‘¥ Workerè¿›ç¨‹æ•°: {config.workers}")
    print(f"ğŸ”§ æ¨ç†å¼•æ“: {config.inference_engine}")
    print("\nå¯åŠ¨ Gunicorn æœåŠ¡å™¨...")
    
    # å¯åŠ¨ Gunicorn
    wsgi.run()


def check_dependencies():
    """æ£€æŸ¥ä¾èµ–"""
    print("ğŸ” æ£€æŸ¥è¿è¡Œç¯å¢ƒ...")
    
    # æ£€æŸ¥Pythonç‰ˆæœ¬
    if sys.version_info < (3, 8):
        print("âŒ éœ€è¦ Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬")
        sys.exit(1)
    
    print(f"âœ… Pythonç‰ˆæœ¬: {sys.version}")
    
    # æ£€æŸ¥å¿…éœ€çš„åŒ…
    required_packages = [
        ('flask', 'flask'), 
        ('flask-cors', 'flask_cors'), 
        ('loguru', 'loguru'), 
        ('pydantic', 'pydantic'),
        ('python-dotenv', 'dotenv'), 
        ('psutil', 'psutil'), 
        ('requests', 'requests')
    ]
    
    missing_packages = []
    for package_name, import_name in required_packages:
        try:
            __import__(import_name)
        except ImportError:
            missing_packages.append(package_name)
    
    if missing_packages:
        print(f"âŒ ç¼ºå°‘å¿…éœ€çš„åŒ…: {', '.join(missing_packages)}")
        print("è¯·è¿è¡Œ: pip install -r requirements.txt")
        sys.exit(1)
    
    print("âœ… åŸºç¡€ä¾èµ–æ£€æŸ¥é€šè¿‡")
    
    # æ£€æŸ¥æ¨ç†å¼•æ“
    from src.utils.platform_detector import PlatformDetector
    
    detector = PlatformDetector()
    platform_info = detector.get_platform_info()
    optimal_engine = detector.detect_best_engine()
    
    print(f"âœ… æ£€æµ‹åˆ°å¹³å°: {platform_info['system']} ({platform_info['machine']})")
    print(f"âœ… æ¨èæ¨ç†å¼•æ“: {optimal_engine}")
    
    # æ£€æŸ¥æ¨ç†å¼•æ“å¯ç”¨æ€§
    if optimal_engine == 'vllm':
        try:
            import vllm
            print(f"âœ… VLLM å¯ç”¨ (ç‰ˆæœ¬: {vllm.__version__})")
        except ImportError:
            print("âš ï¸ VLLM ä¸å¯ç”¨ï¼Œå°†å›é€€åˆ° llama.cpp")
    
    elif optimal_engine == 'mlx':
        try:
            import mlx.core as mx
            import mlx_lm
            print(f"âœ… MLX å¯ç”¨")
        except ImportError:
            print("âš ï¸ MLX ä¸å¯ç”¨ï¼Œå°†å›é€€åˆ° llama.cpp")
    
    try:
        import llama_cpp
        print(f"âœ… llama.cpp å¯ç”¨ (ç‰ˆæœ¬: {llama_cpp.__version__})")
    except ImportError:
        print("âŒ llama.cpp ä¸å¯ç”¨")
        print("è¯·å®‰è£…: pip install llama-cpp-python")
        sys.exit(1)


def setup_environment():
    """è®¾ç½®ç¯å¢ƒ"""
    print("âš™ï¸ è®¾ç½®è¿è¡Œç¯å¢ƒ...")
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    directories = ['logs', 'models', 'cache']
    for directory in directories:
        Path(directory).mkdir(exist_ok=True)
        print(f"âœ… ç¡®ä¿ç›®å½•å­˜åœ¨: {directory}/")
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not Path('.env').exists():
        print("âš ï¸ æœªæ‰¾åˆ° .env é…ç½®æ–‡ä»¶")
        print("å°†ä½¿ç”¨é»˜è®¤é…ç½®ï¼Œå»ºè®®å¤åˆ¶ .env.example å¹¶æ ¹æ®éœ€è¦ä¿®æ”¹")
    else:
        print("âœ… æ‰¾åˆ° .env é…ç½®æ–‡ä»¶")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='VLLM è·¨å¹³å°æ¨ç†æœåŠ¡')
    parser.add_argument(
        '--mode', 
        choices=['dev', 'prod'], 
        default='dev',
        help='è¿è¡Œæ¨¡å¼ (dev: å¼€å‘æ¨¡å¼, prod: ç”Ÿäº§æ¨¡å¼)'
    )
    parser.add_argument(
        '--skip-check', 
        action='store_true',
        help='è·³è¿‡ä¾èµ–æ£€æŸ¥'
    )
    parser.add_argument(
        '--config', 
        type=str,
        help='æŒ‡å®šé…ç½®æ–‡ä»¶è·¯å¾„'
    )
    
    args = parser.parse_args()
    
    print("ğŸš€ VLLM è·¨å¹³å°æ¨ç†æœåŠ¡")
    print("=" * 50)
    
    # è®¾ç½®é…ç½®æ–‡ä»¶
    if args.config:
        os.environ['CONFIG_FILE'] = args.config
    
    # ç¯å¢ƒæ£€æŸ¥
    if not args.skip_check:
        check_dependencies()
        setup_environment()
        print("=" * 50)
    
    # å¯åŠ¨æœåŠ¡
    try:
        if args.mode == 'dev':
            run_development()
        else:
            run_production()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æœåŠ¡å·²åœæ­¢")
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()