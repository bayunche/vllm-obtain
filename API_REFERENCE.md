# ğŸ”Œ API å‚è€ƒæ–‡æ¡£

## OpenAI å…¼å®¹æ¥å£

### åŸºç¡€ä¿¡æ¯
- **Base URL**: `http://localhost:8001/v1`
- **è®¤è¯**: æœ¬åœ°æœåŠ¡æ— éœ€API Keyï¼Œå¡«å…¥ä»»æ„å€¼å³å¯
- **æ ¼å¼**: 100% OpenAI API å…¼å®¹

---

## ğŸ¯ æ¨¡å‹ç®¡ç†

### GET /v1/models
åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹

**å“åº”ç¤ºä¾‹:**
```json
{
  "object": "list",
  "data": [
    {
      "id": "qwen-0.5b",
      "object": "model",
      "created": 1693363200,
      "owned_by": "local",
      "permission": [],
      "root": "qwen-0.5b",
      "parent": null
    }
  ]
}
```

### GET /v1/models/{model_id}
è·å–ç‰¹å®šæ¨¡å‹ä¿¡æ¯

---

## ğŸ’¬ èŠå¤©è¡¥å…¨

### POST /v1/chat/completions
èŠå¤©è¡¥å…¨æ¥å£ï¼Œæ”¯æŒåŠ¨æ€æ¨¡å‹åˆ‡æ¢

**è¯·æ±‚ä½“:**
```json
{
  "model": "qwen-0.5b",          // æ¨¡å‹åç§°ï¼Œæ”¯æŒåŠ¨æ€åˆ‡æ¢
  "messages": [                   // å¯¹è¯æ¶ˆæ¯
    {
      "role": "system",
      "content": "You are a helpful assistant."
    },
    {
      "role": "user", 
      "content": "Hello!"
    }
  ],
  "max_tokens": 100,             // å¯é€‰ï¼šæœ€å¤§tokenæ•°
  "temperature": 0.7,            // å¯é€‰ï¼šåˆ›é€ æ€§å‚æ•°
  "top_p": 0.9,                  // å¯é€‰ï¼šæ ¸é‡‡æ ·å‚æ•°
  "stream": false,               // å¯é€‰ï¼šæµå¼å“åº”
  "stop": ["\\n"]                // å¯é€‰ï¼šåœæ­¢è¯
}
```

**å“åº”ç¤ºä¾‹:**
```json
{
  "id": "chatcmpl-abc123",
  "object": "chat.completion",
  "created": 1693363200,
  "model": "qwen-0.5b",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Hello! How can I help you today?"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 20,
    "completion_tokens": 10,
    "total_tokens": 30
  },
  "system_fingerprint": "fp_1693363200"
}
```

### æµå¼å“åº”
è®¾ç½® `"stream": true` å¯ç”¨æµå¼å“åº”

**å“åº”æ ¼å¼:**
```
data: {"id":"chatcmpl-abc123","object":"chat.completion.chunk","created":1693363200,"model":"qwen-0.5b","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

data: {"id":"chatcmpl-abc123","object":"chat.completion.chunk","created":1693363200,"model":"qwen-0.5b","choices":[{"index":0,"delta":{"content":"Hello"},"finish_reason":null}]}

data: [DONE]
```

---

## ğŸ“ æ–‡æœ¬è¡¥å…¨

### POST /v1/completions
ä¼ ç»Ÿæ–‡æœ¬è¡¥å…¨æ¥å£

**è¯·æ±‚ä½“:**
```json
{
  "model": "qwen-0.5b",
  "prompt": "The capital of France is",
  "max_tokens": 50,
  "temperature": 0.7,
  "top_p": 0.9,
  "stream": false
}
```

---

## ğŸ”§ ç³»ç»Ÿç®¡ç†

### GET /health
æœåŠ¡å¥åº·æ£€æŸ¥

**å“åº”ç¤ºä¾‹:**
```json
{
  "status": "healthy",
  "timestamp": 1693363200,
  "manager_initialized": true,
  "engines": {
    "mlx": {
      "status": "healthy",
      "loaded_models": 2
    }
  },
  "models": 2,
  "issues": []
}
```

### GET /v1/system/status
è·å–è¯¦ç»†ç³»ç»ŸçŠ¶æ€

**å“åº”ç¤ºä¾‹:**
```json
{
  "initialized": true,
  "total_engines": 1,
  "registered_models": 3,
  "loaded_models": 2,
  "max_concurrent_models": 3,
  "models": [
    {
      "name": "qwen-0.5b",
      "engine_type": "mlx",
      "status": "loaded",
      "loaded_at": "2024-01-01T12:00:00",
      "memory_usage": "2.1GB",
      "context_length": 4096
    }
  ],
  "engines": {
    "mlx": {
      "status": "healthy",
      "memory_usage": "4.2GB"
    }
  }
}
```

---

## ğŸš¨ é”™è¯¯å¤„ç†

### é”™è¯¯æ ¼å¼
æ‰€æœ‰é”™è¯¯éƒ½éµå¾ªOpenAIæ ¼å¼ï¼š

```json
{
  "error": {
    "message": "æ¨¡å‹æœªæ‰¾åˆ°: invalid-model",
    "type": "not_found_error",
    "param": null,
    "code": "model_not_found"
  }
}
```

### å¸¸è§é”™è¯¯ç 

| HTTPçŠ¶æ€ç  | é”™è¯¯ç±»å‹ | æè¿° |
|-----------|---------|------|
| 400 | invalid_request_error | è¯·æ±‚æ ¼å¼é”™è¯¯ |
| 404 | not_found_error | æ¨¡å‹æˆ–èµ„æºæœªæ‰¾åˆ° |
| 429 | rate_limit_error | è¯·æ±‚é¢‘ç‡è¿‡é«˜ |
| 500 | server_error | æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ |
| 503 | server_error | æœåŠ¡æœªå°±ç»ª |

---

## ğŸ”„ åŠ¨æ€æ¨¡å‹åˆ‡æ¢

### ç‰¹æ€§è¯´æ˜
- **é›¶åœæœºåˆ‡æ¢**: è¿è¡Œæ—¶åŠ¨æ€åŠ è½½/å¸è½½æ¨¡å‹
- **è‡ªåŠ¨åŠ è½½**: è°ƒç”¨æœªåŠ è½½æ¨¡å‹æ—¶è‡ªåŠ¨åŠ è½½
- **æ™ºèƒ½å¸è½½**: è¶…å‡ºå¹¶å‘é™åˆ¶æ—¶è‡ªåŠ¨å¸è½½æ—§æ¨¡å‹
- **å¹¶å‘å®‰å…¨**: å¤šè¯·æ±‚å¹¶å‘è®¿é—®åŒä¸€æ¨¡å‹å®‰å…¨

### åˆ‡æ¢ç¤ºä¾‹
```python
import openai

client = openai.OpenAI(
    api_key="not-needed",
    base_url="http://localhost:8001/v1"
)

# ç¬¬ä¸€æ¬¡è°ƒç”¨è‡ªåŠ¨åŠ è½½æ¨¡å‹
response1 = client.chat.completions.create(
    model="qwen-0.5b",
    messages=[{"role": "user", "content": "Hello"}]
)

# åˆ‡æ¢åˆ°å¦ä¸€ä¸ªæ¨¡å‹ï¼Œè‡ªåŠ¨åŠ è½½
response2 = client.chat.completions.create(
    model="GLM-4.5V",
    messages=[{"role": "user", "content": "ä½ å¥½"}]
)
```

---

## ğŸ› ï¸ å®¢æˆ·ç«¯é›†æˆ

### Python OpenAI Client
```python
import openai

client = openai.OpenAI(
    api_key="sk-dummy",  # ä»»æ„å€¼
    base_url="http://localhost:8001/v1"
)

response = client.chat.completions.create(
    model="qwen-0.5b",
    messages=[{"role": "user", "content": "Hello"}]
)
```

### cURL
```bash
curl -X POST http://localhost:8001/v1/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer sk-dummy" \\
  -d '{
    "model": "qwen-0.5b",
    "messages": [{"role": "user", "content": "Hello"}]
  }'
```

### n8n èŠ‚ç‚¹é…ç½®
1. **Connection**: Custom
2. **Base URL**: `http://localhost:8001/v1`
3. **API Key**: ä»»æ„å€¼ (å¦‚: `sk-local`)
4. **Model**: åœ¨èŠ‚ç‚¹ä¸­é€‰æ‹©å…·ä½“æ¨¡å‹

### LangChain
```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    api_key="sk-dummy",
    base_url="http://localhost:8001/v1",
    model="qwen-0.5b"
)

response = llm.invoke("Hello!")
```

---

## âš¡ æ€§èƒ½ä¼˜åŒ–

### å¹¶å‘æ§åˆ¶
- é»˜è®¤æ”¯æŒæœ€å¤š3ä¸ªæ¨¡å‹åŒæ—¶è¿è¡Œ
- é€šè¿‡ `MAX_CONCURRENT_MODELS` é…ç½®è°ƒæ•´
- è‡ªåŠ¨LRUæ¸…ç†ç­–ç•¥

### ç¼“å­˜æœºåˆ¶
- æ¨¡å‹æ¨ç†ç»“æœç¼“å­˜
- å¯é€šè¿‡é…ç½®å¯ç”¨/ç¦ç”¨
- TTLè¿‡æœŸè‡ªåŠ¨æ¸…ç†

### å†…å­˜ç®¡ç†
- æ™ºèƒ½å†…å­˜ç›‘æ§
- ä½å†…å­˜æ—¶è‡ªåŠ¨å¸è½½æ¨¡å‹
- æ”¯æŒå†…å­˜é™åˆ¶é…ç½®