# 📋 更新日志

## [2.0.0] - 2025-01-01

### 🔥 重大特性
- **动态模型管理**: 支持运行时热切换模型，无需重启服务
- **智能内存管理**: 自动加载/卸载模型，避免内存溢出
- **并发安全锁**: 修复MLX引擎并发访问导致的段错误
- **多模型注册**: 自动发现和注册所有可用模型

### ✨ 新增功能
- 添加 `register_models.py` 工具自动发现模型
- 支持3个模型同时运行 (`MAX_CONCURRENT_MODELS=3`)
- 新增完整的API参考文档
- 新增生产部署指南
- 增强错误处理和日志记录

### 🛠️ 改进优化
- 重构项目文档结构，移除冗余文档
- 修复API超时问题，从30秒增加到300秒
- 优化配置验证，支持所有.env文件参数
- 改进平台检测和引擎自动选择
- 增强测试覆盖率和兼容性测试

### 🐛 Bug修复
- 修复MLX引擎并发访问导致的段错误
- 修复配置加载失败的28个验证错误
- 修复HTML测试报告CSS格式错误
- 修复依赖检查脚本使用系统Python的问题
- 修复API响应超时和空错误消息问题

### 📚 文档更新
- 全新的README.md，突出动态模型切换特性
- 完整的API参考文档 (API_REFERENCE.md)
- 详细的部署指南 (DEPLOYMENT.md)  
- 清理了13个过时的文档文件

### 🏗️ 项目结构优化
- 重组目录结构，脚本分类存放
- 添加.gitignore和LICENSE文件
- 创建archive目录归档历史文档
- 优化工具脚本的组织方式

---

## [1.0.0] - 2024-08-21

### 🎯 初始版本
- 基础VLLM跨平台推理服务
- OpenAI API兼容接口
- 支持MLX、VLLM、LlamaCpp三种引擎
- 基础模型管理功能
- 跨平台部署支持

### 🔧 支持的引擎
- **MLX**: Apple Silicon优化引擎
- **VLLM**: Linux GPU高性能引擎
- **LlamaCpp**: 通用CPU推理引擎

### 📊 测试验证
- Mac Studio M3 Ultra测试通过
- 基础并发测试和兼容性验证
- OpenAI API格式100%兼容

---

## 📋 版本说明

### 版本号规则
- **主版本号**: 重大架构变更或不兼容更新
- **次版本号**: 新功能添加或重要改进  
- **修订号**: Bug修复和小型改进

### 升级指南
详见 [DEPLOYMENT.md](DEPLOYMENT.md) 的升级部分。

### 支持策略
- **当前版本**: 完整支持和更新
- **前一版本**: 安全更新和重要Bug修复
- **更早版本**: 仅安全更新