#!/usr/bin/env python3
"""
æµ‹è¯•OpenAI APIå®Œå…¨å…¼å®¹æ€§
ä½¿ç”¨çœŸå®çš„OpenAI Pythonå®¢æˆ·ç«¯åº“è¿›è¡Œæµ‹è¯•
"""

import asyncio
import json
import base64
import sys
import os
import time
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import openai
import requests


# é…ç½®æµ‹è¯•å®¢æˆ·ç«¯ï¼ˆæŒ‡å‘æœ¬åœ°æœåŠ¡ï¼‰
TEST_BASE_URL = "http://localhost:8001/v1"
TEST_API_KEY = "test-key"  # æœ¬åœ°æœåŠ¡å¯èƒ½ä¸éœ€è¦çœŸå®çš„APIå¯†é’¥


class OpenAICompatibilityTester:
    """OpenAIå…¼å®¹æ€§æµ‹è¯•å™¨"""
    
    def __init__(self, base_url: str = TEST_BASE_URL, api_key: str = TEST_API_KEY):
        self.client = openai.OpenAI(
            base_url=base_url,
            api_key=api_key
        )
        self.base_url = base_url
        self.headers = {"Authorization": f"Bearer {api_key}"}
    
    def test_models_endpoint(self):
        """æµ‹è¯•æ¨¡å‹åˆ—è¡¨æ¥å£"""
        print("\n=== æµ‹è¯• GET /v1/models ===")
        
        try:
            # ä½¿ç”¨requestsç›´æ¥æµ‹è¯•
            response = requests.get(f"{self.base_url}/models", headers=self.headers)
            print(f"çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                data = response.json()
                print(f"è¿”å›æ ¼å¼æ­£ç¡®: {data.get('object') == 'list'}")
                print(f"æ¨¡å‹æ•°é‡: {len(data.get('data', []))}")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«OpenAIæ ‡å‡†æ¨¡å‹
                model_ids = [model['id'] for model in data.get('data', [])]
                openai_models = ['gpt-4', 'gpt-3.5-turbo', 'text-davinci-003']
                has_openai_models = any(model in model_ids for model in openai_models)
                print(f"åŒ…å«OpenAIæ¨¡å‹: {has_openai_models}")
                
                print("âœ… æ¨¡å‹æ¥å£æµ‹è¯•é€šè¿‡")
                return True
            else:
                print(f"âŒ æ¨¡å‹æ¥å£æµ‹è¯•å¤±è´¥: {response.status_code}")
                print(response.text)
                return False
                
        except Exception as e:
            print(f"âŒ æ¨¡å‹æ¥å£æµ‹è¯•å¼‚å¸¸: {e}")
            return False
    
    def test_chat_completions(self):
        """æµ‹è¯•èŠå¤©è¡¥å…¨æ¥å£"""
        print("\n=== æµ‹è¯• POST /v1/chat/completions ===")
        
        test_cases = [
            # åŸºç¡€èŠå¤©æµ‹è¯•
            {
                "name": "åŸºç¡€èŠå¤©",
                "data": {
                    "model": "gpt-3.5-turbo",
                    "messages": [
                        {"role": "user", "content": "Hello!"}
                    ]
                }
            },
            
            # ç³»ç»Ÿæ¶ˆæ¯æµ‹è¯•
            {
                "name": "ç³»ç»Ÿæ¶ˆæ¯",
                "data": {
                    "model": "gpt-4",
                    "messages": [
                        {"role": "system", "content": "You are a helpful assistant."},
                        {"role": "user", "content": "What is 2+2?"}
                    ],
                    "temperature": 0.7,
                    "max_tokens": 100
                }
            },
            
            # å¤šè½®å¯¹è¯æµ‹è¯•
            {
                "name": "å¤šè½®å¯¹è¯",
                "data": {
                    "model": "gpt-3.5-turbo",
                    "messages": [
                        {"role": "user", "content": "Hi"},
                        {"role": "assistant", "content": "Hello! How can I help you?"},
                        {"role": "user", "content": "Tell me a joke"}
                    ],
                    "temperature": 0.9
                }
            },
            
            # Base64å†…å®¹æµ‹è¯•
            {
                "name": "Base64å†…å®¹",
                "data": {
                    "model": "gpt-3.5-turbo",
                    "messages": [
                        {"role": "user", "content": base64.b64encode("Hello, world!".encode()).decode()}
                    ]
                }
            }
        ]
        
        success_count = 0
        
        for case in test_cases:
            print(f"\n  æµ‹è¯•: {case['name']}")
            try:
                response = requests.post(
                    f"{self.base_url}/chat/completions",
                    headers={**self.headers, "Content-Type": "application/json"},
                    json=case['data']
                )
                
                print(f"    çŠ¶æ€ç : {response.status_code}")
                
                if response.status_code == 200:
                    data = response.json()
                    
                    # éªŒè¯å“åº”æ ¼å¼
                    required_fields = ['id', 'object', 'created', 'model', 'choices', 'usage']
                    missing_fields = [field for field in required_fields if field not in data]
                    
                    if not missing_fields:
                        print(f"    âœ… å“åº”æ ¼å¼æ­£ç¡®")
                        print(f"    å“åº”å†…å®¹: {data['choices'][0]['message']['content'][:50]}...")
                        success_count += 1
                    else:
                        print(f"    âŒ ç¼ºå°‘å­—æ®µ: {missing_fields}")
                else:
                    print(f"    âŒ è¯·æ±‚å¤±è´¥: {response.text}")
                    
            except Exception as e:
                print(f"    âŒ å¼‚å¸¸: {e}")
        
        print(f"\nèŠå¤©è¡¥å…¨æµ‹è¯•: {success_count}/{len(test_cases)} é€šè¿‡")
        return success_count == len(test_cases)
    
    def test_completions(self):
        """æµ‹è¯•æ–‡æœ¬è¡¥å…¨æ¥å£"""
        print("\n=== æµ‹è¯• POST /v1/completions ===")
        
        test_cases = [
            # åŸºç¡€è¡¥å…¨æµ‹è¯•
            {
                "name": "åŸºç¡€è¡¥å…¨",
                "data": {
                    "model": "text-davinci-003",
                    "prompt": "The quick brown fox",
                    "max_tokens": 50
                }
            },
            
            # å¤šä¸ªpromptæµ‹è¯•
            {
                "name": "å¤šä¸ªprompt",
                "data": {
                    "model": "text-davinci-002",
                    "prompt": ["Hello", "World"],
                    "max_tokens": 30
                }
            },
            
            # å‚æ•°æµ‹è¯•
            {
                "name": "è¯¦ç»†å‚æ•°",
                "data": {
                    "model": "text-davinci-003",
                    "prompt": "Explain quantum computing in simple terms:",
                    "max_tokens": 100,
                    "temperature": 0.5,
                    "top_p": 0.9,
                    "frequency_penalty": 0.2,
                    "presence_penalty": 0.1,
                    "stop": ["\n\n"]
                }
            }
        ]
        
        success_count = 0
        
        for case in test_cases:
            print(f"\n  æµ‹è¯•: {case['name']}")
            try:
                response = requests.post(
                    f"{self.base_url}/completions",
                    headers={**self.headers, "Content-Type": "application/json"},
                    json=case['data']
                )
                
                print(f"    çŠ¶æ€ç : {response.status_code}")
                
                if response.status_code == 200:
                    data = response.json()
                    
                    # éªŒè¯å“åº”æ ¼å¼
                    required_fields = ['id', 'object', 'created', 'model', 'choices', 'usage']
                    missing_fields = [field for field in required_fields if field not in data]
                    
                    if not missing_fields:
                        print(f"    âœ… å“åº”æ ¼å¼æ­£ç¡®")
                        print(f"    å“åº”å†…å®¹: {data['choices'][0]['text'][:50]}...")
                        success_count += 1
                    else:
                        print(f"    âŒ ç¼ºå°‘å­—æ®µ: {missing_fields}")
                else:
                    print(f"    âŒ è¯·æ±‚å¤±è´¥: {response.text}")
                    
            except Exception as e:
                print(f"    âŒ å¼‚å¸¸: {e}")
        
        print(f"\næ–‡æœ¬è¡¥å…¨æµ‹è¯•: {success_count}/{len(test_cases)} é€šè¿‡")
        return success_count == len(test_cases)
    
    def test_streaming(self):
        """æµ‹è¯•æµå¼å“åº”"""
        print("\n=== æµ‹è¯•æµå¼å“åº” ===")
        
        try:
            # æµ‹è¯•æµå¼èŠå¤©
            print("  æµ‹è¯•æµå¼èŠå¤©è¡¥å…¨...")
            
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers={**self.headers, "Content-Type": "application/json"},
                json={
                    "model": "gpt-3.5-turbo",
                    "messages": [{"role": "user", "content": "Count to 5"}],
                    "stream": True
                },
                stream=True
            )
            
            print(f"    çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                chunks_received = 0
                for line in response.iter_lines():
                    if line:
                        line_text = line.decode('utf-8')
                        if line_text.startswith('data: '):
                            data_part = line_text[6:]  # ç§»é™¤ 'data: ' å‰ç¼€
                            
                            if data_part == '[DONE]':
                                break
                                
                            try:
                                chunk_data = json.loads(data_part)
                                if 'choices' in chunk_data:
                                    chunks_received += 1
                                    if chunks_received <= 3:  # åªæ˜¾ç¤ºå‰3ä¸ªchunk
                                        content = chunk_data['choices'][0].get('delta', {}).get('content', '')
                                        print(f"    Chunk {chunks_received}: {content}")
                            except json.JSONDecodeError:
                                pass
                
                print(f"    âœ… æ”¶åˆ° {chunks_received} ä¸ªæ•°æ®å—")
                return True
            else:
                print(f"    âŒ æµå¼è¯·æ±‚å¤±è´¥: {response.text}")
                return False
                
        except Exception as e:
            print(f"    âŒ æµå¼æµ‹è¯•å¼‚å¸¸: {e}")
            return False
    
    def test_multimodal_content(self):
        """æµ‹è¯•å¤šæ¨¡æ€å†…å®¹"""
        print("\n=== æµ‹è¯•å¤šæ¨¡æ€å†…å®¹ ===")
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾ç‰‡ï¼ˆ1x1åƒç´ çš„çº¢è‰²PNGï¼‰
        test_image_bytes = b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x00\x01\x00\x00\x00\x01\x08\x02\x00\x00\x00\x90wS\xde\x00\x00\x00\x0cIDATx\x9cc\xf8\x0f\x00\x00\x01\x01\x00\x00\xad\xad\xacI\x00\x00\x00\x00IEND\xaeB`\x82'
        test_image_b64 = base64.b64encode(test_image_bytes).decode()
        
        try:
            # æµ‹è¯•OpenAI Vision APIæ ¼å¼
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers={**self.headers, "Content-Type": "application/json"},
                json={
                    "model": "gpt-4-vision-preview",
                    "messages": [
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "text",
                                    "text": "What's in this image?"
                                },
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/png;base64,{test_image_b64}",
                                        "detail": "high"
                                    }
                                }
                            ]
                        }
                    ]
                }
            )
            
            print(f"  çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                data = response.json()
                print(f"  âœ… å¤šæ¨¡æ€å†…å®¹å¤„ç†æˆåŠŸ")
                print(f"  å“åº”: {data['choices'][0]['message']['content'][:100]}...")
                return True
            else:
                print(f"  âŒ å¤šæ¨¡æ€è¯·æ±‚å¤±è´¥: {response.text}")
                return False
                
        except Exception as e:
            print(f"  âŒ å¤šæ¨¡æ€æµ‹è¯•å¼‚å¸¸: {e}")
            return False
    
    def test_error_handling(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        print("\n=== æµ‹è¯•é”™è¯¯å¤„ç† ===")
        
        error_cases = [
            # ç¼ºå°‘modelå‚æ•°
            {
                "name": "ç¼ºå°‘modelå‚æ•°",
                "data": {"messages": [{"role": "user", "content": "test"}]},
                "expected_status": 400
            },
            
            # ç¼ºå°‘messageså‚æ•°
            {
                "name": "ç¼ºå°‘messageså‚æ•°",
                "data": {"model": "gpt-3.5-turbo"},
                "expected_status": 400
            },
            
            # æ— æ•ˆçš„temperature
            {
                "name": "æ— æ•ˆçš„temperature",
                "data": {
                    "model": "gpt-3.5-turbo",
                    "messages": [{"role": "user", "content": "test"}],
                    "temperature": 3.0  # è¶…å‡ºèŒƒå›´
                },
                "expected_status": 400
            },
            
            # ä¸å­˜åœ¨çš„æ¨¡å‹
            {
                "name": "ä¸å­˜åœ¨çš„æ¨¡å‹",
                "data": {
                    "model": "nonexistent-model",
                    "messages": [{"role": "user", "content": "test"}]
                },
                "expected_status": 404
            }
        ]
        
        success_count = 0
        
        for case in error_cases:
            print(f"\n  æµ‹è¯•: {case['name']}")
            try:
                response = requests.post(
                    f"{self.base_url}/chat/completions",
                    headers={**self.headers, "Content-Type": "application/json"},
                    json=case['data']
                )
                
                print(f"    çŠ¶æ€ç : {response.status_code}")
                expected = case.get('expected_status')
                
                if expected and response.status_code == expected:
                    # æ£€æŸ¥é”™è¯¯å“åº”æ ¼å¼
                    if response.status_code >= 400:
                        try:
                            error_data = response.json()
                            if 'error' in error_data:
                                print(f"    âœ… é”™è¯¯æ ¼å¼æ­£ç¡®: {error_data['error']['message']}")
                                success_count += 1
                            else:
                                print(f"    âŒ é”™è¯¯æ ¼å¼ä¸æ­£ç¡®")
                        except json.JSONDecodeError:
                            print(f"    âŒ é”™è¯¯å“åº”ä¸æ˜¯JSONæ ¼å¼")
                    else:
                        success_count += 1
                elif not expected:  # æ²¡æœ‰æŒ‡å®šæœŸæœ›çŠ¶æ€ç ï¼Œåªè¦ä¸æ˜¯500å°±ç®—æˆåŠŸ
                    if response.status_code < 500:
                        success_count += 1
                        print(f"    âœ… é”™è¯¯å¤„ç†æ­£ç¡®")
                    else:
                        print(f"    âŒ æœåŠ¡å™¨å†…éƒ¨é”™è¯¯")
                else:
                    print(f"    âŒ çŠ¶æ€ç ä¸åŒ¹é…ï¼ŒæœŸæœ›: {expected}")
                    
            except Exception as e:
                print(f"    âŒ å¼‚å¸¸: {e}")
        
        print(f"\né”™è¯¯å¤„ç†æµ‹è¯•: {success_count}/{len(error_cases)} é€šè¿‡")
        return success_count == len(error_cases)
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("=" * 60)
        print("å¼€å§‹OpenAI APIå…¼å®¹æ€§æµ‹è¯•")
        print(f"æµ‹è¯•ç›®æ ‡: {self.base_url}")
        print("=" * 60)
        
        tests = [
            ("æ¨¡å‹æ¥å£", self.test_models_endpoint),
            ("èŠå¤©è¡¥å…¨", self.test_chat_completions),
            ("æ–‡æœ¬è¡¥å…¨", self.test_completions),
            ("æµå¼å“åº”", self.test_streaming),
            ("å¤šæ¨¡æ€å†…å®¹", self.test_multimodal_content),
            ("é”™è¯¯å¤„ç†", self.test_error_handling)
        ]
        
        results = []
        for test_name, test_func in tests:
            try:
                result = test_func()
                results.append((test_name, result))
            except Exception as e:
                print(f"\nâŒ {test_name}æµ‹è¯•å‡ºç°å¼‚å¸¸: {e}")
                results.append((test_name, False))
        
        # æ±‡æ€»ç»“æœ
        print("\n" + "=" * 60)
        print("æµ‹è¯•ç»“æœæ±‡æ€»:")
        print("=" * 60)
        
        passed = 0
        for test_name, result in results:
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            print(f"{test_name:15} {status}")
            if result:
                passed += 1
        
        print("\n" + "=" * 60)
        print(f"æ€»è®¡: {passed}/{len(results)} é¡¹æµ‹è¯•é€šè¿‡")
        
        if passed == len(results):
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼APIå®Œå…¨å…¼å®¹OpenAIè§„èŒƒ")
        else:
            print(f"âš ï¸  {len(results) - passed} é¡¹æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤")
        
        print("=" * 60)
        
        return passed == len(results)


def check_service_status(base_url: str = TEST_BASE_URL):
    """æ£€æŸ¥æœåŠ¡çŠ¶æ€"""
    try:
        response = requests.get(f"{base_url.replace('/v1', '')}/health", timeout=5)
        if response.status_code == 200:
            return True
    except:
        pass
    return False


def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥æœåŠ¡æ˜¯å¦è¿è¡Œ
    if not check_service_status():
        print(f"âŒ æœåŠ¡æœªè¿è¡Œæˆ–æ— æ³•è®¿é—®: {TEST_BASE_URL}")
        print("è¯·ç¡®ä¿æœåŠ¡å·²å¯åŠ¨å¹¶ç›‘å¬åœ¨ http://localhost:8001")
        sys.exit(1)
    
    # è¿è¡Œæµ‹è¯•
    tester = OpenAICompatibilityTester()
    success = tester.run_all_tests()
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()